import sys

def main (subject):
     subject = str(subject)
     print(subject)

     """247-DATA-Classification-PhonemicStructureInWhisperSpeech.ipynb

     Automatically generated by Colaboratory.

     Original file is located at
     https://colab.research.google.com/drive/1TKj61zNY1BBBa263Ds7-fWR6geSxbhrE

     ## Make sure to change the directory and file names below before running !!!
     """

     #dirname = '/content/drive/MyDrive/Research/Hasson/Ariel/whisper/whisper_gpt2_datums/'
     #dirname_plot = "/content/drive/MyDrive/COURSES/2023_SPRING/thesis_figs"

     dirname = '/scratch/gpfs/aditis/247-encoding/whisper_gpt2_datums/'
     dirname_plot = "/scratch/gpfs/aditis/247-encoding/results/figures/"

     #load in the embeddings datums
     model = "encoder"
     layer = 4

     whisper_filename = f"_whisper-tiny.en-encoder_word_layer_0{layer}.pkl"
     base_df_filename = f"-whisper-tiny.en-encoder_word_base_df.pkl"

     """## import packages

     """


     # Commented out IPython magic to ensure Python compatibility.
     import numpy as np
     import torch
     import pandas as pd
     from sklearn.decomposition import PCA
     import matplotlib.pyplot as plt

     import pickle
     from scipy.spatial.distance import pdist, squareform
     from scipy.stats import zscore
     import plotly.express as px

     from scipy.cluster.hierarchy import dendrogram, linkage
     from scipy.cluster.hierarchy import cophenet
     from scipy.spatial.distance import pdist


     # %matplotlib inline
     # %autosave 180

     import nltk
     nltk.download('punkt')
     nltk.download('averaged_perceptron_tagger')
     nltk.download('universal_tagset')

     def run_pca(pca_to, df):
          pca = PCA(n_components=pca_to, svd_solver="auto", whiten=True)

          df_emb = df["phonemic_embeddings"]
          embs = np.vstack(df_emb.values)

          pca_output = pca.fit_transform(embs)
          df["phonemic_embeddings"] = pca_output.tolist()

          return df

     """# merge embedding and base pickle and only get words that glove has"""

     # load in data
     with open(f"{dirname}625{whisper_filename}", 'rb') as f:
          whisper_data = pickle.load(f)

     with open(f"{dirname}625{base_df_filename}",'rb') as pfile:
          whisper_base = pd.read_pickle(pfile)

     whisper_base = whisper_base.dropna(subset=["onset", "offset"])
     whisper_base.reset_index( drop=True, inplace=True)
     whisper_df = pd.DataFrame(whisper_data)

     subjs_remaining = ['676', '798', '7170']

     for subj in subjs_remaining:
          with open(f"{dirname}{subj}{whisper_filename}", 'rb') as f:
               temp_data_df = pickle.load(f)
          temp_data_df = pd.DataFrame(temp_data_df)

          with open(f"{dirname}{subj}{base_df_filename}",'rb') as pfile:
               temp_base_df = pd.read_pickle(pfile)
          temp_base_df = temp_base_df.dropna(subset=["onset", "offset"])
          temp_base_df.reset_index( drop=True, inplace=True)
     
          whisper_df = pd.concat([whisper_df,temp_data_df])
          whisper_base = pd.concat([whisper_base,temp_base_df])


     def ave_emb(datum):
          print("Averaging embeddings across tokens")

          # calculate mean embeddings
          def mean_emb(embs):
               return np.array(embs.values.tolist()).mean(axis=0).tolist()

          mean_embs = datum.groupby(["adjusted_onset", "word"], sort=False)[
               "embeddings"
          ].apply(lambda x: mean_emb(x))
          mean_embs = pd.DataFrame(mean_embs)

          # replace embeddings
          idx = (
               datum.groupby(["adjusted_onset", "word"], sort=False)["token_idx"].transform(
                    min
               )
               == datum["token_idx"]
          )
          datum = datum[idx]
          mean_embs.set_index(datum.index, inplace=True)
          datum2 = datum.copy()  # setting copy to avoid warning
          datum2.loc[:, "embeddings"] = mean_embs.embeddings
          datum = datum2  # reassign back to datum

          return datum

     whisper_df = pd.concat([whisper_base, whisper_df], axis = 1)
     whisper_avg_df = ave_emb(whisper_df)
     whisper_avg_df  = whisper_avg_df.rename(columns = {"index": "word_index"})

     const = 384
     emb1 = []
     emb2 = []
     emb3 = []
     emb4 = []
     for emb in whisper_avg_df["embeddings"]:
          emb1.append(emb[0:3*const])
          emb2.append(emb[3*const:6*const])
          emb3.append(emb[6*const:9*const])
          # emb4.append(emb[9*const:12*const])

     whisper_avg_df = whisper_avg_df[whisper_avg_df['embeddings'].notna()]
     whisper_avg_df = whisper_avg_df.assign(phoneme1_emb=emb1)
     whisper_avg_df = whisper_avg_df.assign(phoneme2_emb=emb2)
     whisper_avg_df = whisper_avg_df.assign(phoneme3_emb=emb3)
     #whisper_avg_df = whisper_avg_df.assign(phoneme4_emb=emb4)

     """## create glove embedding """

     def get_vector(x, glove):
          try:
               return glove.get_vector(x)
          except KeyError:
               return None

     import gensim.downloader as api
     glove = api.load('glove-wiki-gigaword-50')
     glove_emb = whisper_avg_df.word.apply(lambda x: get_vector(x.lower(), glove))

     merged_dataset = whisper_avg_df.assign(glove=glove_emb)
     merged_dataset = merged_dataset[merged_dataset['glove'].notna()]
     merged_dataset.word = merged_dataset.word.str.lower()

     """# filter out common words"""

     merged_dataset['occurences'] = merged_dataset['word'].map(merged_dataset['word'].value_counts())
     merged_dataset = merged_dataset[merged_dataset['occurences'] < 10]

     merged_dataset.drop_duplicates('word', inplace=True, ignore_index = True)

     """# Get the part of speech for each word

     """

     words_orig, part_of_speech = zip(*nltk.pos_tag(merged_dataset.word, tagset='universal'))
     merged_dataset = merged_dataset.assign(part_of_speech=part_of_speech)

     function_content_dict = {'ADP':'function', 'CONJ':'function', 'DET':'function', 'PRON':'function', "PRT":'function', 'ADJ':"content", 'ADV':"content", 'NOUN':"content", "NUM":"content", 'VERB':"content", 'X':"unknown"}
     function_content = merged_dataset.apply(lambda x: function_content_dict.get(x['part_of_speech']),axis=1)

     merged_dataset = merged_dataset.assign(function_content=function_content)

     """[link text](https:// [link text](https://))# break words down into phonemes"""

     #!curl -OL https://github.com/Alexir/CMUdict/raw/master/cmudict-0.7b

     ## original categorization, including specific vowel catergorization
     #phoneset = ['AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'B', 'CH', 'D', 'DH', 'EH', 'ER', 'EY', 'F' , 'G', 'HH', 'IH', 'IY', 'JH', 'K', 'L',  'M', 'N' , 'NG', 'OW', 'OY', 'P',  'R', 'S',  'SH', 'T', 'TH', 'UH', 'UW', 'V', 'W', 'Y', 'Z', 'ZH']
     #place_of_articulation   = ['low-central', 'low-front', 'mid-central', 'mid-back', 'high-back', 'high-front', 'bilabial', 'post-alveolar', 'alveolar', 'inter-dental', 'mid-front', 'mid-central', 'mid-front','alveolar','velar', 'glotal', 'high-front', 'high-front', 'post-alveolar', 'velar', 'alveolar', 'bilabial', 'alveolar', 'velar', 'high-back', 'high-front', 'bilabial', 'alveolar', 'alveolar', 'post-alveolar', 'alveolar', 'inter-dental', 'high-back', 'high-back', 'labio-dental', 'bilabial', 'palatal', 'alveolar', 'post-alveolar']
     #manner_of_articulation  = ['lax', 'lax', 'lax', 'lax', 'lax', 'tense', 'stop', 'affricate', 'stop', 'fricative', 'lax', 'tense', 'tense', 'flap', 'stop','fricative', 'lax', 'tense', 'affricate', 'stop', 'lateral-liquid', 'nasal', 'nasal', 'nasal', 'lax', 'lax', 'stop', 'retroflex-liquid', 'fricative', 'fricative', 'stop', 'fricative', 'lax', 'tense', 'fricative', 'glide', 'glide', 'fricative', 'fricative']

     phoneset_categorizations = pd.read_csv(f'{dirname}phoneset.csv')
     phoneset                 = phoneset_categorizations.iloc[:,0].values
     place_of_articulation    = phoneset_categorizations.iloc[:,1].values
     manner_of_articulation   = phoneset_categorizations.iloc[:,2].values
     voiced_or_voiceless      = phoneset_categorizations.iloc[:,3].values

     place_of_articulation_dict  = dict(zip(phoneset, place_of_articulation))
     manner_of_articulation_dict = dict(zip(phoneset, manner_of_articulation))
     voiced_or_voiceless_dict    = dict(zip(phoneset, voiced_or_voiceless))

     cmu_dict_filename = f"{dirname}cmudict-0.7b"

     pdict = {}
     with open(cmu_dict_filename, 'r', encoding='ISO-8859-1') as f:
          for line in f.readlines():
               if not line.startswith(';;;'):
                    parts = line.rstrip().split()
                    word = parts[0].lower()
                    phones = [phone.rstrip('012') for phone in parts[1:]]
                    pdict[word] = phones

     words2phonemes = []
     words2phonemes = merged_dataset.apply(lambda x: pdict.get(x['word'].lower()),axis=1)
     #merged_dataset = merged_dataset.assign(words2phonemes=words2phonemes)

     indx = 1

     words  = []
     word_index = []
     phonemes = []
     phonemic_embeddings = []
     phonemic_index = []
     manner_articulation_save = []
     place_of_articulation_save = []
     voiced_or_voiceless_save = []
     function_or_content_save = []
     part_of_speech_save = []

     for count, phonems in enumerate(words2phonemes):
          if phonems is None:
               continue
          for i in range(np.min([indx,len(phonems)])): # dont save more embeddings than there are phonemes in a word
               name = f"phoneme{i+1}_emb"
               phonemes.append(phonems[i])
               phonemic_embeddings.append(np.array(merged_dataset.iloc[count][name]))
               words.append(merged_dataset.iloc[count]["word"])
               word_index.append(merged_dataset.iloc[count]["word_index"])
               phonemic_index.append(i)
               manner_articulation_save.append(manner_of_articulation_dict[phonems[i]])
               place_of_articulation_save.append(place_of_articulation_dict[phonems[i]])
               voiced_or_voiceless_save.append(voiced_or_voiceless_dict[phonems[i]])
               function_or_content_save.append(merged_dataset.iloc[count]["function_content"])
               part_of_speech_save.append(merged_dataset.iloc[count]["part_of_speech"])


     #phonemic_embeddings = np.vstack(phonemic_embeddings)

     phonemic_dict = {'phonemes':phonemes, 'phonemic_embeddings':phonemic_embeddings,
                              'manner_articulation': manner_articulation_save,
                    'place_of_articulation': place_of_articulation_save,
                    'voiced_or_voiceless': voiced_or_voiceless_save}
     phonemic_df = pd.DataFrame(data = phonemic_dict)
     phonemic_df = run_pca(250, phonemic_df)

     """# creating the classification models"""

     X = list(phonemic_df['phonemic_embeddings'])
     y = list(phonemic_df['phonemes'])

     from sklearn.model_selection import train_test_split
     X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)
     iterations = 1000
     solver_name = "lbfgs"
     print("iterations: " + iterations)
     print("solver_name: " + solver_name)

     from sklearn.linear_model import LogisticRegression
     logreg = LogisticRegression(max_iter=iterations,solver = solver_name)
     logreg.fit(X_train, y_train)
     print("predict phoneme")
     print('Accuracy of Logistic regression classifier on training set: {:.2f}'
          .format(logreg.score(X_train, y_train)))
     print('Accuracy of Logistic regression classifier on test set: {:.2f}'
          .format(logreg.score(X_test, y_test)))

     from sklearn.dummy import DummyClassifier
     dummy_clf = DummyClassifier(strategy="most_frequent")
     dummy_clf.fit(X_train, y_train)
     print("predict phonemes dummy classifier")
     print('Accuracy of Logistic regression classifier on training set: {:.2f}'
          .format(dummy_clf.score(X_train, y_train)))
     print('Accuracy of Logistic regression classifier on test set: {:.2f}'
          .format(dummy_clf.score(X_test, y_test)))

     X = list(phonemic_df['phonemic_embeddings'])
     y = list(phonemic_df['manner_articulation'])
     X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)
     logreg = LogisticRegression(max_iter=iterations,solver = solver_name)
     logreg.fit(X_train, y_train)
     print("predict manner of articulation")
     print('Accuracy of Logistic regression classifier on training set: {:.2f}'
          .format(logreg.score(X_train, y_train)))
     print('Accuracy of Logistic regression classifier on test set: {:.2f}'
          .format(logreg.score(X_test, y_test)))

     from sklearn.dummy import DummyClassifier
     dummy_clf = DummyClassifier(strategy="most_frequent")
     dummy_clf.fit(X_train, y_train)
     print("predict manner of articulation dummy classifier")
     print('Accuracy of Logistic regression classifier on training set: {:.2f}'
          .format(dummy_clf.score(X_train, y_train)))
     print('Accuracy of Logistic regression classifier on test set: {:.2f}'
          .format(dummy_clf.score(X_test, y_test)))

     X = list(phonemic_df['phonemic_embeddings'])
     y = list(phonemic_df['place_of_articulation'])
     X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)
     logreg = LogisticRegression(max_iter=iterations,solver = solver_name)
     logreg.fit(X_train, y_train)
     print("predict place of articulation")
     print('Accuracy of Logistic regression classifier on training set: {:.2f}'
          .format(logreg.score(X_train, y_train)))
     print('Accuracy of Logistic regression classifier on test set: {:.2f}'
          .format(logreg.score(X_test, y_test)))

     from sklearn.dummy import DummyClassifier
     dummy_clf = DummyClassifier(strategy="most_frequent")
     dummy_clf.fit(X_train, y_train)
     print("predict place_of_articulation dummy classifier")
     print('Accuracy of Logistic regression classifier on training set: {:.2f}'
          .format(dummy_clf.score(X_train, y_train)))
     print('Accuracy of Logistic regression classifier on test set: {:.2f}'
          .format(dummy_clf.score(X_test, y_test)))

     X = list(phonemic_df['phonemic_embeddings'])
     y = list(phonemic_df['voiced_or_voiceless'])
     X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)
     logreg = LogisticRegression(max_iter=iterations,solver = solver_name)
     logreg.fit(X_train, y_train)
     print("predict voiced_or_voiceless")
     print('Accuracy of Logistic regression classifier on training set: {:.2f}'
          .format(logreg.score(X_train, y_train)))
     print('Accuracy of Logistic regression classifier on test set: {:.2f}'
          .format(logreg.score(X_test, y_test)))

     from sklearn.dummy import DummyClassifier
     dummy_clf = DummyClassifier(strategy="most_frequent")
     dummy_clf.fit(X_train, y_train)
     print("predict voiced_or_voiceless dummy classifier")
     print('Accuracy of Logistic regression classifier on training set: {:.2f}'
          .format(dummy_clf.score(X_train, y_train)))
     print('Accuracy of Logistic regression classifier on test set: {:.2f}'
          .format(dummy_clf.score(X_test, y_test)))

if __name__ == "__main__":
    main(sys.argv[1])
